{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "data_set_url = 'https://static-content.springer.com/esm/art%3A10.1038%2Fncomms5212/MediaObjects/41467_2014_BFncomms5212_MOESM1045_ESM.txt'\n",
    "data = urlopen(data_set_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = []\n",
    "for line in data:\n",
    "    data_row = line.decode().rstrip()\n",
    "    my_data.append([term for term in data_row.split('\\t')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MeSH Symptom Term', 'MeSH Disease Term', 'PubMed occurrence',\n",
       "       'TFIDF score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(my_data[1:], columns = my_data[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Diseases: 4219\n",
      "# Unique Symptoms: 322\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['symptom','disease','n','score']\n",
    "df['symptom'] = df['symptom'].astype('category')\n",
    "df['disease'] = df['disease'].astype('category')\n",
    "df['n'] = df['n'].astype('int')\n",
    "df['score'] = df['score'].astype('float')\n",
    "df = df.sort_values(by=['disease', 'symptom', 'n', 'score'])\n",
    "possible_diseases = set(df['disease'])\n",
    "possible_symptoms = set(df['symptom'])\n",
    "disease_names = list(possible_diseases)\n",
    "print('# Unique Diseases: {}'.format(len(possible_diseases)))\n",
    "print('# Unique Symptoms: {}'.format(len(possible_symptoms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('symptom_disease_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['symptom_encod'] = df['symptom'].cat.codes\n",
    "df['disease_encod'] = df['disease'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symptom</th>\n",
       "      <th>disease</th>\n",
       "      <th>n</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Development Disorders</td>\n",
       "      <td>22q11 Deletion Syndrome</td>\n",
       "      <td>1</td>\n",
       "      <td>2.486567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Retardation</td>\n",
       "      <td>22q11 Deletion Syndrome</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olfaction Disorders</td>\n",
       "      <td>22q11 Deletion Syndrome</td>\n",
       "      <td>1</td>\n",
       "      <td>2.288230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respiratory Sounds</td>\n",
       "      <td>22q11 Deletion Syndrome</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virilism</td>\n",
       "      <td>46, XX Disorders of Sex Development</td>\n",
       "      <td>1</td>\n",
       "      <td>2.227056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          symptom                              disease  n  \\\n",
       "0  Language Development Disorders              22q11 Deletion Syndrome  1   \n",
       "1              Mental Retardation              22q11 Deletion Syndrome  1   \n",
       "2             Olfaction Disorders              22q11 Deletion Syndrome  1   \n",
       "3              Respiratory Sounds              22q11 Deletion Syndrome  1   \n",
       "4                        Virilism  46, XX Disorders of Sex Development  1   \n",
       "\n",
       "      score  \n",
       "0  2.486567  \n",
       "1  0.905447  \n",
       "2  2.288230  \n",
       "3  1.639269  \n",
       "4  2.227056  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('symptom_disease_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "diseases = list(set(df['disease']))\n",
    "diseases_csv = pd.DataFrame([['disease_id'] + diseases])\n",
    "diseases_csv.to_csv('disease_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease To Symptom Classifier\n",
    "\n",
    "## Path To Completion\n",
    "\n",
    "1. Reformat data-frame to have symp_1, ..., symp_n, disease_i for each row, with the values being the occurence of symptom j within 1 <= j <= n for disease i.\n",
    "\n",
    "2. Create simulated training and testing data for each disease which match original data's original frequency distribution\n",
    "\n",
    "3. Run random forests model on data\n",
    "\n",
    "## Step 1 - Reformat Data-Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_encod = set(df['symptom_encod'])\n",
    "new_col_names = [\"\"]*len(symptom_encod)\n",
    "\n",
    "for i, symp_i in enumerate(symptom_encod):\n",
    "    new_col_names[i] = \"symp_\" + str(symp_i)\n",
    "\n",
    "new_col_names.append(\"disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_encod = set(df['disease_encod'])\n",
    "new_df = pd.DataFrame([[0]*len(new_col_names) for _ in range(len(disease_encod))], columns=new_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test grabbing 'n'\n",
    "df[(df.disease_encod == 1) & (df.symptom_encod == 312)][['n']].iloc[0]['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(new_df.columns)\n",
    "def edit_row(rnge):\n",
    "    start, end = rnge\n",
    "    for disease in range(start, end+1):\n",
    "        new_row = [0]*num_cols\n",
    "        new_row[-1] = disease\n",
    "        \n",
    "        for j in range(num_cols-1):\n",
    "            res = df[(df['disease_encod'] == disease) & (df['symptom_encod'] == j)]\n",
    "            if len(res) > 0:\n",
    "                new_row[j] = res[['n']].iloc[0]['n']\n",
    "\n",
    "        # write over row in df\n",
    "        new_df.iloc[disease] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for re-processing\n",
    "import threading\n",
    "\n",
    "def start_threads(threads):\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "def join_threads(threads):\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "def multi_thread(n_rows, n_threads, proc):\n",
    "    if n_threads < 1:\n",
    "        return\n",
    "    \n",
    "    jump = n_rows // n_threads\n",
    "    \n",
    "    threads = []\n",
    "    for i in range(0, n_rows, jump):\n",
    "        # split range -> [start, end] --> feed to proc\n",
    "        start, end = i, i+jump\n",
    "        \n",
    "        # extend for final thread\n",
    "        if i // jump == n_threads:\n",
    "            end = n_rows-1\n",
    "            \n",
    "        t = threading.Thread(target=proc, args=((start,end),))\n",
    "        threads.append(t)\n",
    "        \n",
    "    start_threads(threads)\n",
    "    join_threads(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates the re-formatted data-frame!\n",
    "# multi_thread(len(new_df), 4, edit_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment when processing again\n",
    "# new_df.to_csv('symptom_disease_dataset_reformatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df = pd.read_csv('symptom_disease_dataset_reformatted.csv')\n",
    "\n",
    "# make columns floating point data types\n",
    "for col in new_df.columns[:-1]:\n",
    "    new_df[col] = new_df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "# time-complexity: O(N*max(M, log(N))) \n",
    "def prune_df(df, top_num_diseases):\n",
    "    h = []\n",
    "    \n",
    "    # time-complexity: O(N*max(M, log(N))) \n",
    "    # O(N) - rows\n",
    "    for i in range(len(df)):\n",
    "        # O(M) - cols\n",
    "        row_sum = sum(df.iloc[i][:-1])\n",
    "        # O(log(N))\n",
    "        heapq.heappush(h, (-row_sum, i))\n",
    "    \n",
    "    # capture top diseases based on symptom frequency\n",
    "    # time-complexity: O(N) * O(1) = O(N)\n",
    "    top_diseases = [heapq.heappop(h)[1] for i in range(top_num_diseases)]\n",
    "    \n",
    "    # create new data frame of top diseases\n",
    "    top_df = df[df.disease.isin(top_diseases)]\n",
    "    for col in top_df.columns[:-1]:\n",
    "        # if symptom has 0 occurrences, delete\n",
    "        if not top_df[col].any():\n",
    "            del top_df[col]\n",
    "    \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor item in apples: # time-complexity: O(N)\\n    print(item)\\n\\n# time-complexity: O(N*M * log(M))\\nfor item in apples:\\n    # O(N)\\n    for buyer in buyers:\\n        print(buyer)\\n    \\n    # O(M*log(M))\\n    sort(buyers)\\n\\n\\nfor i in range(len(matrix)): # time-complexity: O(N*M)\\n    for j in range(len(matrix[0])):\\n        print(matrix[i][j])\\n\\nprint(apples[0]) # time-complexity: O(1)\\n\\n# binary search time-complexity: O(log(N))\\n\\n# sort a unorder list: O(N*log(N))\\n\\n# heap (min-heap/max-heap)\\n# add elm to heap: O(log(N))\\n# grab/pop your min-value from min-heap: O(1) # constant\\n\\n# add element to a list: O(1)\\n# find element in list: O(N)\\n\\n# O(1) <= O(log(N)) <= O(N) <= O(N*log(N)) <= O(N^2) <= ...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for item in apples: # time-complexity: O(N)\n",
    "    print(item)\n",
    "\n",
    "# time-complexity: O(N*M * log(M))\n",
    "for item in apples:\n",
    "    # O(N)\n",
    "    for buyer in buyers:\n",
    "        print(buyer)\n",
    "    \n",
    "    # O(M*log(M))\n",
    "    sort(buyers)\n",
    "\n",
    "\n",
    "for i in range(len(matrix)): # time-complexity: O(N*M)\n",
    "    for j in range(len(matrix[0])):\n",
    "        print(matrix[i][j])\n",
    "\n",
    "print(apples[0]) # time-complexity: O(1)\n",
    "\n",
    "# binary search time-complexity: O(log(N))\n",
    "\n",
    "# sort a unorder list: O(N*log(N))\n",
    "\n",
    "# heap (min-heap/max-heap)\n",
    "# add elm to heap: O(log(N))\n",
    "# grab/pop your min-value from min-heap: O(1) # constant\n",
    "\n",
    "# add element to a list: O(1)\n",
    "# find element in list: O(N)\n",
    "\n",
    "# O(1) <= O(log(N)) <= O(N) <= O(N*log(N)) <= O(N^2) <= ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symp_0</th>\n",
       "      <th>symp_1</th>\n",
       "      <th>symp_2</th>\n",
       "      <th>symp_3</th>\n",
       "      <th>symp_4</th>\n",
       "      <th>symp_5</th>\n",
       "      <th>symp_6</th>\n",
       "      <th>symp_7</th>\n",
       "      <th>symp_8</th>\n",
       "      <th>symp_9</th>\n",
       "      <th>...</th>\n",
       "      <th>symp_311</th>\n",
       "      <th>symp_312</th>\n",
       "      <th>symp_313</th>\n",
       "      <th>symp_314</th>\n",
       "      <th>symp_315</th>\n",
       "      <th>symp_316</th>\n",
       "      <th>symp_317</th>\n",
       "      <th>symp_320</th>\n",
       "      <th>symp_321</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>4836.0</td>\n",
       "      <td>2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9199.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      symp_0  symp_1  symp_2  symp_3  symp_4  symp_5  symp_6  symp_7  symp_8  \\\n",
       "216      2.0     3.0   109.0     2.0     0.0     0.0     0.0     0.0     0.0   \n",
       "830      7.0     4.0   314.0     1.0     1.0     1.0     0.0     0.0     0.0   \n",
       "904      0.0     3.0     0.0     0.0     1.0     0.0    12.0     1.0     0.0   \n",
       "982      2.0    17.0    25.0     0.0     0.0     2.0     0.0     0.0     1.0   \n",
       "1878     7.0    24.0    15.0     0.0     1.0     1.0     0.0     0.0     2.0   \n",
       "2447     1.0     0.0     0.0     5.0     0.0     2.0     3.0     1.0     8.0   \n",
       "2781     1.0    10.0     7.0     0.0     2.0     2.0     0.0     0.0     1.0   \n",
       "2908    69.0    76.0     2.0     0.0     0.0     1.0     2.0     0.0     7.0   \n",
       "3533     1.0     3.0     0.0     0.0     0.0     0.0     6.0     0.0     4.0   \n",
       "4129     0.0     1.0     0.0     0.0     0.0     0.0    52.0     4.0     0.0   \n",
       "\n",
       "      symp_9   ...     symp_311  symp_312  symp_313  symp_314  symp_315  \\\n",
       "216      0.0   ...         11.0       0.0       2.0       0.0       0.0   \n",
       "830     97.0   ...         12.0       1.0       3.0       0.0       1.0   \n",
       "904      2.0   ...        117.0       0.0      65.0       0.0       3.0   \n",
       "982   1854.0   ...          1.0       2.0      51.0       4.0       0.0   \n",
       "1878  1316.0   ...         53.0      11.0      56.0       0.0       1.0   \n",
       "2447     2.0   ...          0.0       2.0     103.0       1.0       1.0   \n",
       "2781   110.0   ...          3.0       6.0      10.0       2.0       1.0   \n",
       "2908     0.0   ...         13.0       0.0      21.0       0.0       0.0   \n",
       "3533     1.0   ...         10.0       0.0      30.0       0.0       0.0   \n",
       "4129     3.0   ...         21.0       0.0    9199.0      31.0       0.0   \n",
       "\n",
       "      symp_316  symp_317  symp_320  symp_321  disease  \n",
       "216        0.0       5.0       0.0       4.0      216  \n",
       "830        0.0       6.0      33.0      49.0      830  \n",
       "904       13.0       2.0       2.0       1.0      904  \n",
       "982        0.0      24.0     390.0     671.0      982  \n",
       "1878       0.0      29.0     137.0     420.0     1878  \n",
       "2447       2.0      23.0       7.0       9.0     2447  \n",
       "2781       0.0      25.0    1486.0    4836.0     2781  \n",
       "2908       4.0     110.0      10.0      26.0     2908  \n",
       "3533       0.0      40.0      11.0       6.0     3533  \n",
       "4129       0.0       3.0       0.0       2.0     4129  \n",
       "\n",
       "[10 rows x 305 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_df = prune_df(new_df, 10)\n",
    "top_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5ec651b3f544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disease'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_cols = new_df.columns[:-1].tolist()\n",
    "X = new_df[pd.Index(x_cols)]\n",
    "y = new_df['disease']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#X_train.reshape(-1,1)\n",
    "def model_predict(X_train, y_train, X_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "def print_accuracy(y_test, y_pred):\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(y_test, model_predict(X_train, y_train, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Artificially Augment the data\n",
    "- 1. Identify distribution of data\n",
    "- 2. Randomly create new data and append to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def bar_plot(x, y):\n",
    "    fig = go.Figure([go.Bar(x=x,y=y)])\n",
    "    fig.show()\n",
    "\n",
    "def disease_symptom_dist(disease_id):\n",
    "    disease = new_df[new_df['disease'] == disease_id]\n",
    "    y_vals = disease[disease.columns[:-1]].iloc[0].tolist()\n",
    "    \n",
    "    # create bar chart\n",
    "    bar_plot(disease.columns[:-1], y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def apply_noise(df, mu=0, sigma=0.1, round=True):\n",
    "    n_rows, n_cols = len(df), len(df.columns)\n",
    "    noise = np.random.normal(mu, sigma, [n_rows, n_cols])\n",
    "    return df + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not good enough\n",
    "# capture mu and sigma for each symptom\n",
    "def get_mu(col):\n",
    "    return sum(col)/len(col) if len(col) else 0\n",
    "\n",
    "def get_sigma(col, mu=0.1):\n",
    "    n = len(col)\n",
    "    return sum((col-mu)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite new_df by taking row proportions\n",
    "def row_proportion(row):\n",
    "    row_sum = sum(row[:-1])\n",
    "    for i, item in enumerate(row[:-1]):\n",
    "        row[i] = item*1.0 / (row_sum if row_sum else 1)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_row_proportion(bounds):\n",
    "    start, end = bounds\n",
    "    for i in range(start, end+1):\n",
    "        new_df.iloc[i] = row_proportion(new_df.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.00041000000000046555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konner/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/konner/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tik = time.clock()\n",
    "### Applies row proportions\n",
    "# multi_thread(len(new_df), 5, apply_row_proportion)\n",
    "tok = time.clock()\n",
    "print('Total time: {}'.format(tok-tik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('symptom_disease_dataset_row_proportions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symp_0</th>\n",
       "      <th>symp_1</th>\n",
       "      <th>symp_2</th>\n",
       "      <th>symp_3</th>\n",
       "      <th>symp_4</th>\n",
       "      <th>symp_5</th>\n",
       "      <th>symp_6</th>\n",
       "      <th>symp_7</th>\n",
       "      <th>symp_8</th>\n",
       "      <th>symp_9</th>\n",
       "      <th>...</th>\n",
       "      <th>symp_313</th>\n",
       "      <th>symp_314</th>\n",
       "      <th>symp_315</th>\n",
       "      <th>symp_316</th>\n",
       "      <th>symp_317</th>\n",
       "      <th>symp_318</th>\n",
       "      <th>symp_319</th>\n",
       "      <th>symp_320</th>\n",
       "      <th>symp_321</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symp_0  symp_1  symp_2  symp_3  symp_4  symp_5  symp_6  symp_7  symp_8  \\\n",
       "0     0.0  0.0000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0  0.0000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0  0.0000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0  0.0625     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0  0.0000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   symp_9   ...     symp_313  symp_314  symp_315  symp_316  symp_317  \\\n",
       "0     0.0   ...          0.0       0.0       0.0       0.0       0.0   \n",
       "1     0.0   ...          0.0       0.0       0.0       0.0       0.0   \n",
       "2     0.0   ...          0.0       0.0       0.0       0.0       0.0   \n",
       "3     0.0   ...          0.0       0.0       0.0       0.0       0.0   \n",
       "4     0.0   ...          0.2       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   symp_318  symp_319  symp_320  symp_321  disease  \n",
       "0       0.0       0.0    0.0000    0.0000      0.0  \n",
       "1       0.0       0.0    0.0000    0.0000      1.0  \n",
       "2       0.0       0.0    0.0000    0.0000      2.0  \n",
       "3       0.0       0.0    0.0625    0.0625      3.0  \n",
       "4       0.0       0.0    0.2000    0.0000      4.0  \n",
       "\n",
       "[5 rows x 323 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import row proportions\n",
    "#\n",
    "# EXECUTE THIS DOWN FOR ARTIFICAL DATA CREATION\n",
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "new_df = pd.read_csv('symptom_disease_dataset_row_proportions.csv')\n",
    "\n",
    "for col in new_df.columns[:-1]:\n",
    "    new_df[col] = new_df[col].astype('float')\n",
    "    \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row-proportions complete!\n",
    "\n",
    "Now what?\n",
    "\n",
    "Artificial data creation...\n",
    "\n",
    "Let's say for a given disease, we have proportions: `[0.1, 0.2, 0.7]`.\n",
    "\n",
    "We randomly sample a number between 1-1000 for each symptom, we get: `[100, 250, 400]`\n",
    "\n",
    "Now apply the proportions: `[10, 50, 280]`\n",
    "\n",
    "Recalculate the row-proportions: `[.027, 0.205, .788]` This is our new row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_artificial_row(row):\n",
    "    n = len(row)\n",
    "    artificial_row = [0.0]*n\n",
    "    \n",
    "    # create new artificial counts\n",
    "    for i, actual_proportion in enumerate(row[:-1]):\n",
    "        artificial_row[i] = random.randint(0,1000) * actual_proportion\n",
    "    \n",
    "    # add disease to artificial row\n",
    "    artificial_row[-1] = row[-1]\n",
    "    \n",
    "    return row_proportion(artificial_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking good, let's multithread and enhance!!\n",
    "\n",
    "# create massive data frame, where each piece of data has 500 additional rows of artificial data\n",
    "N_ADDITIONAL = 2\n",
    "\n",
    "# stretch new_df\n",
    "old_n_rows, old_n_cols = len(new_df), len(new_df.columns)\n",
    "new_n_rows = old_n_rows + old_n_rows * N_ADDITIONAL\n",
    "\n",
    "\n",
    "def apply_artificial_data(bounds):\n",
    "    print(bounds)\n",
    "    start, end = bounds\n",
    "    # Bounds is (0, 838019/5)\n",
    "    # need to skip N_ADDITIONAL at a time\n",
    "    i = start\n",
    "    while i < end:\n",
    "        # assign initial row\n",
    "        big_data.iloc[i] = new_df.iloc[i//(N_ADDITIONAL+1)]\n",
    "        \n",
    "        # add N_ADDITIONAL new rows of data\n",
    "        j = 1\n",
    "        while i+j < end and j < N_ADDITIONAL+1:\n",
    "            big_data.iloc[i+j] = get_artificial_row(new_df.iloc[i])\n",
    "            j += 1\n",
    "        \n",
    "        # move ahead N_ADDITIONAL\n",
    "        i += N_ADDITIONAL+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.DataFrame([[0]*len(new_df.columns) for _ in range(10)], columns=new_df.columns)\n",
    "#multi_thread(len(test), 1, apply_artificial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows(df, bounds):\n",
    "    start, end = bounds\n",
    "    for row_idx in range(start, end):\n",
    "        print_row(df.iloc[row_idx])\n",
    "\n",
    "def print_row(row):\n",
    "    for item in row:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbig_data = [[0]*old_n_cols for _ in range(new_n_rows)]\\ni, jump = 0, len(big_data)//10\\n\\nbig_data_1 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_2 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_3 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_4 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_5 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_6 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_7 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_8 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_9 = big_data.iloc[i:i+jump]\\ni += jump\\nbig_data_10 = big_data.iloc[i:]\\ni += jump\\nbig_data_1.to_csv('big_data_1.csv')\\nbig_data_2.to_csv('big_data_2.csv')\\nbig_data_3.to_csv('big_data_3.csv')\\nbig_data_4.to_csv('big_data_4.csv')\\nbig_data_5.to_csv('big_data_5.csv')\\nbig_data_6.to_csv('big_data_6.csv')\\nbig_data_7.to_csv('big_data_7.csv')\\nbig_data_8.to_csv('big_data_8.csv')\\nbig_data_9.to_csv('big_data_9.csv')\\nbig_data_10.to_csv('big_data_10.csv')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 10 big data csvs\n",
    "\"\"\"\n",
    "big_data = [[0]*old_n_cols for _ in range(new_n_rows)]\n",
    "i, jump = 0, len(big_data)//10\n",
    "\n",
    "big_data_1 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_2 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_3 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_4 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_5 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_6 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_7 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_8 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_9 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_10 = big_data.iloc[i:]\n",
    "i += jump\n",
    "big_data_1.to_csv('big_data_1.csv')\n",
    "big_data_2.to_csv('big_data_2.csv')\n",
    "big_data_3.to_csv('big_data_3.csv')\n",
    "big_data_4.to_csv('big_data_4.csv')\n",
    "big_data_5.to_csv('big_data_5.csv')\n",
    "big_data_6.to_csv('big_data_6.csv')\n",
    "big_data_7.to_csv('big_data_7.csv')\n",
    "big_data_8.to_csv('big_data_8.csv')\n",
    "big_data_9.to_csv('big_data_9.csv')\n",
    "big_data_10.to_csv('big_data_10.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "big_data_1 = pd.read_csv('big_data_1.csv')\n",
    "big_data_2 = pd.read_csv('big_data_2.csv')\n",
    "big_data_3 = pd.read_csv('big_data_3.csv')\n",
    "big_data_4 = pd.read_csv('big_data_4.csv')\n",
    "big_data_5 = pd.read_csv('big_data_5.csv')\n",
    "big_data_6 = pd.read_csv('big_data_6.csv')\n",
    "big_data_7 = pd.read_csv('big_data_7.csv')\n",
    "big_data_8 = pd.read_csv('big_data_8.csv')\n",
    "big_data_9 = pd.read_csv('big_data_9.csv')\n",
    "big_data_10 = pd.read_csv('big_data_10.csv')\n",
    "\n",
    "big_data = big_data_1.append(big_data_2, ignore_index=True).append(big_data_3, ignore_index=True).append(big_data_4, ignore_index=True).append(big_data_5, ignore_index=True).append(big_data_6, ignore_index=True).append(big_data_7, ignore_index=True).append(big_data_8, ignore_index=True).append(big_data_9, ignore_index=True).append(big_data_10, ignore_index=True)\n",
    "del big_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "Exception in thread Thread-9:\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "        self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "    self.run()\n",
      "  File \"e:\\desktop\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 670, in __setitem__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-579531f5eaf1>\", line 17, in apply_artificial_data\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    iloc._setitem_with_indexer(indexer, value)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1754, in _setitem_with_indexer\n",
      "        return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1496, in _getitem_axis\n",
      "return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1496, in _getitem_axis\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)    \n",
      "return self._getitem_axis(maybe_callable, axis=axis)      File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1496, in _getitem_axis\n",
      "\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1496, in _getitem_axis\n",
      "return self._getitem_axis(maybe_callable, axis=axis)        \n",
      "self._validate_integer(key, axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1437, in _validate_integer\n",
      "    self._validate_integer(key, axis)  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1496, in _getitem_axis\n",
      "\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1437, in _validate_integer\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1437, in _validate_integer\n",
      "raise ValueError(\n",
      "    ValueError: self._validate_integer(key, axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1437, in _validate_integer\n",
      "Must have equal len keys and value when setting with an iterable    \n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError:     single positional indexer is out-of-bounds\n",
      "raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds    self._validate_integer(key, axis)\n",
      "  File \"e:\\desktop\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1437, in _validate_integer\n",
      "\n",
      "raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      ": single positional indexer is out-of-bounds\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n"
     ]
    }
   ],
   "source": [
    "### Run this for artificial data creation!\n",
    "multi_thread(len(big_data), 1, apply_artificial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: execute after artificial data finishes!\n",
    "\n",
    "i, jump = 0, len(big_data)//10\n",
    "\n",
    "big_data_1 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_2 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_3 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_4 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_5 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_6 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_7 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_8 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_9 = big_data.iloc[i:i+jump]\n",
    "i += jump\n",
    "big_data_10 = big_data.iloc[i:]\n",
    "i += jump\n",
    "big_data_1.to_csv('art_data_1.csv')\n",
    "big_data_2.to_csv('art_data_2.csv')\n",
    "big_data_3.to_csv('art_data_3.csv')\n",
    "big_data_4.to_csv('art_data_4.csv')\n",
    "big_data_5.to_csv('art_data_5.csv')\n",
    "big_data_6.to_csv('art_data_6.csv')\n",
    "big_data_7.to_csv('art_data_7.csv')\n",
    "big_data_8.to_csv('art_data_8.csv')\n",
    "big_data_9.to_csv('art_data_9.csv')\n",
    "big_data_10.to_csv('art_data_10.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
